{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:rgb(213,80,0)\">Analyzing FOMC Impact: Leveraging NLP for Sentiment Scores and Swap Rate Predictions</span>\n",
    "\n",
    "The Federal Open Market Committee (FOMC) minutes provide essential insights into the Federal Reserve's monetary policy and economic outlook. By analyzing NLP\\-derived sentiment and thematic scores from these minutes, this example seeks to explore whether these qualitative measures correlate with and potentially predict quantitative movements in federal swap rates. The research utilizes a linear statistical model to assess the predictive power of NLP scores, aiming to provide insights into how market expectations of future interest rates are influenced by FOMC communications. The results could offer valuable implications for enhancing prediction models and decision\\-making processes in financial markets.\n",
    "\n",
    "\n",
    "More details can be found in [Local Functions](#H_D46CB23F).\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "close; clear; clc; warning('off');"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**\n",
    "\n",
    "In this example, we use the FOMC minutes released between March 2000 and July 2024. In the following local functions, we also retrieve the FOMC text data in the HTML form from webpage directly.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "[data, reldate] = clean(2000:2024);"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sentiment Analysis on FOMC minutes**\n",
    "\n",
    "To avoid the runtime, we load the trained sentiment scores. If you are the first time running FinBERT model, you will need to download the pretrained model. The instructions can be found [here](https://www.mathworks.com/matlabcentral/fileexchange/107375-transformer-models).\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "todo = false;\n",
    "if todo\n",
    "    % load the FinBert\n",
    "    mdl = finbert;\n",
    "    tokenizer = mdl.Tokenizer;\n",
    "    parameters = mdl.Parameters;\n",
    "    scores = fnbt(jdata, mdl, tokenizer, parameters);\n",
    "else\n",
    "    load(\"scores.mat\"); % the scores we got\n",
    "end"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regression Analysis**\n",
    "\n",
    "This example is to investigate the swap rate using the statistical methods.\n",
    "\n",
    "\n",
    "We hypothesize that the future swap rate is influenced by the current swap rate and the VIX rates from the latest two terms. Based on the assumption, we develop a regression model. To further enhance the model, we incorporate sentiment scores derived from the FOMC minutes, aiming to illustrate their additional impact on the model's explanatory power.\n",
    "\n",
    "<a name=\"H_08969E51\"></a>\n",
    "\n",
    "### Swap Rates\n",
    "\n",
    "In this example, we used 2\\-year daily/weekly federal swap rates from 2 sources, due to the limited access. In the following steps, we have to merge the 2 pieces together.\n",
    "\n",
    "-  Source 1: starting from September 30 2009: Bloomberg (swap\\-libor.xlsx).\n",
    "-  Source 2: starting from July 3 2000: [Federal Reserve Bank St.Louis](https://fred.stlouisfed.org/series/DSWP2) (DSWP2.csv & WSWP2.csv).\n",
    "\n",
    "We used source 1 to fill the time periods not covered by source 2.\n",
    "\n",
    "\n",
    "The dataset scores is less than rates, due to different frequencies. To match the length of the dataset rates, we applied the forward filling, replacing the missing values with the last observed value. By switching <samp>d</samp> and <samp>w,</samp> we can obtain the daily and weekly basis data. You may find some details of pairing in the local functions section.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "Dregress = merge(scores, \"d\");\n",
    "Wregress = merge(scores, \"w\");"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"H_1163BD1B\"></a>\n",
    "\n",
    "### **Statistical Analysis**\n",
    "\n",
    "The data obtained from \"merge\" function is a matrix.\n",
    "\n",
    "\n",
    "For \"Dmdl\\_2\" and \"Wmdl\\_2\", the first column contains the dates, the second column contains the latest updated swap rates, the third column contains latest updated sentiment scores, the fourth column contains the one previous swap rates, the fifth column contains the latest updated VIX rates, the last column contains the one previous VIX rates.\n",
    "\n",
    "\n",
    "For \"Dmdl\\_1\" and \"Wmdl\\_1\", the columns are identical to \"Dmdl\\_2\" and \"Wmdl\\_2\", except that they do not include the column of sentiment scores.\n",
    "\n",
    "<a name=\"H_D4DF117B\"></a>\n",
    "\n",
    "#### Daily Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "regress = zeros(size(Dregress(:, 2:end)));\n",
    "regress(:, 1) = Dregress(:, 2);\n",
    "regress(:, 2) = Dregress(:, 4);\n",
    "regress(:, 3) = Dregress(:, 3);\n",
    "regress(:, 4:end) = Dregress(:, 5:end);\n",
    "regress = array2table(regress);\n",
    "regress.Properties.VariableNames = {'Future_Swap_Rate', 'Sentiment_Score', 'Current_Swap_Rate', 'Latest_VIX_Rate', 'Second_Latest_VIX_Rate'};\n",
    "Dmdl_1 = fitlm(regress,'Future_Swap_Rate ~ Current_Swap_Rate + Latest_VIX_Rate + Second_Latest_VIX_Rate', Intercept = false)\n",
    "Dmdl_2 = fitlm(regress,'Future_Swap_Rate ~ Sentiment_Score + Current_Swap_Rate + Latest_VIX_Rate + Second_Latest_VIX_Rate', Intercept = false)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"H_32A8F802\"></a>\n",
    "\n",
    "#### Weekly Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "clear regress % clear regress\n",
    "regress = zeros(size(Wregress(:, 2:end)));\n",
    "regress(:, 1) = Wregress(:, 2);\n",
    "regress(:, 2) = Wregress(:, 4);\n",
    "regress(:, 3) = Wregress(:, 3);\n",
    "regress(:, 4:end) = Wregress(:, 5:end);\n",
    "regress = array2table(regress);\n",
    "regress.Properties.VariableNames = {'Future_Swap_Rate', 'Sentiment_Score', 'Current_Swap_Rate', 'Latest_VIX_Rate', 'Second_Latest_VIX_Rate'};\n",
    "Wmdl_1 = fitlm(regress,'Future_Swap_Rate ~ Current_Swap_Rate + Latest_VIX_Rate + Second_Latest_VIX_Rate', Intercept = false)\n",
    "Wmdl_2 = fitlm(regress,'Future_Swap_Rate ~ Sentiment_Score + Current_Swap_Rate + Latest_VIX_Rate + Second_Latest_VIX_Rate', Intercept = false)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"H_BEA3EEC5\"></a>\n",
    "\n",
    "## Model Comparison\n",
    "\n",
    "We compared the adjusted $R^2$ for each model and performed the $F$ test to compare the fitness of two nested models fit with least\\-square regression.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "Models = {'Daily Models w.o. Sentiment Scores';'Daily Models w.t. Sentiment Scores';'Weekly Models w.o. Sentiment Scores';'Weekly Models w.t. Sentiment Scores'};\n",
    "AdjRSquare = [Dmdl_1.Rsquared.Adjusted;Dmdl_2.Rsquared.Adjusted;Wmdl_1.Rsquared.Adjusted;Wmdl_2.Rsquared.Adjusted];\n",
    "TResults = table(Models, AdjRSquare)\n",
    "[Df, Dt] = ft(Dmdl_2, Dmdl_1) % daily basis model\n",
    "[Wf, Wt] = ft(Wmdl_2, Wmdl_1) % weekly basis model"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the results, we can see that the adjusted coefficients of determination $R^2$ show that the models with sentiment scores perform better than models without them. Moreover, the p\\-values obtained from $F$ test show that the models with sentiment scores are statistically significantly different from models without them. That means NLP results derived from FOMC minutes do enhance the prediction of future Federal Swap Rates.\n",
    "\n",
    "<a name=\"H_D46CB23F\"></a>\n",
    "\n",
    "## **Local Functions**\n",
    "### FOMC minutes Data Preprocessing\n",
    "\n",
    "This function retrieves the texts of FOMC minutes directly from web pages. The process begins by obtaining the URLs for these files. For the most recent files, the function retrieves the URLs from [https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm](https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm). For earlier files, the function accesses various websites year by year to gather the necessary URLs.\n",
    "\n",
    "\n",
    "Once the websites are read, the function searches within the HTML content for URLs of the FOMC HTML files. These URLs are embedded within HTML anchor tags. After collecting all the relevant URLs, the function fetches the content from these links and processes the HTML to extract the text of the FOMC minutes.\n",
    "\n",
    "\n",
    "Moreover, FOMC holds at most 8 meetings within a year, this information is used to increase efficiency.\n",
    "\n",
    "### Fetch the FOMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "function txts = fetching(years)\n",
    "    links = cell(length(years)*8, 1); % 8 meetings within a year at most\n",
    "    year = 0;\n",
    "    httpsUrl = \"https://www.federalreserve.gov/monetarypolicy/fomchistorical\"; % obtain earlier minutes first\n",
    "    p1 = '<a href=\\\"\\/fomc/minutes/.{0,8}.htm\\\">'; % possible HTML anchors\n",
    "    p2 = '<a href=\\\"\\/monetarypolicy/fomc.{0,8}.htm\\\">';\n",
    "    p3 = '<a href=\\\"\\/monetarypolicy/fomcminutes.{0,8}.htm\\\">';\n",
    "    pattern = strcat(p1, \"|\", p2, \"|\", p3); % merging the patterns\n",
    "\n",
    "    for i = years\n",
    "        Url = strcat(httpsUrl, string(i), \".htm\");\n",
    "        try\n",
    "            data = webread(Url);\n",
    "        catch ME % once not valid, break the loop, switch the httpsUrl and fetch the latest files instead\n",
    "            break;\n",
    "        end\n",
    "\n",
    "        matchEnd = regexp(data, pattern, 'match', 'all');\n",
    "\n",
    "        for id = 1:length(matchEnd)\n",
    "            link = matchEnd{id};\n",
    "            new_link = strcat('https://www.federalreserve.gov', link(10:(end - 2))); % build the URLs for HTML files\n",
    "            links{id + year*8} = new_link;\n",
    "        end\n",
    "        year = year + 1;\n",
    "    end\n",
    "    links = links(~cellfun(@isempty, links));\n",
    "\n",
    "    httpsUrl = \"https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm\"; % fetch the latest files\n",
    "    data = webread(httpsUrl);\n",
    "    matchEnd = regexp(data, pattern, 'match', 'all');\n",
    "    matchEnd = matchEnd(end:-1:1);\n",
    "    link = cell(length(matchEnd), 1);\n",
    "    i = 1;\n",
    "    while i <= length(matchEnd)\n",
    "        sig = min(i + 7, length(matchEnd));\n",
    "        match = matchEnd(sig:-1:i);\n",
    "\n",
    "        link(i:sig) = match;\n",
    "        i = i + 8;\n",
    "    end\n",
    "\n",
    "    for i = 1:length(link)\n",
    "        l = link{i};\n",
    "        link{i} = strcat('https://www.federalreserve.gov', l(10:(end - 2)));\n",
    "    end\n",
    "\n",
    "    urls = [links; link];\n",
    "\n",
    "    txts = cell(length(urls), 1); % get the texts\n",
    "    for i = 1:length(urls)\n",
    "        url = urls{i};\n",
    "        code = webread(url);\n",
    "        tree = htmlTree(code);\n",
    "        txt = splitlines(extractHTMLText(tree));\n",
    "        txts{i} = txt;\n",
    "    end\n",
    "end"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning\n",
    "\n",
    "Those texts are initially split by paragraphs. All that we need to do is to find certain transition sentences as signals, we then obtain the indices of the paragraphs where the signals are in and get the useful paragraphs we need.\n",
    "\n",
    "\n",
    "How to find those signals is up to you. In this project, we focus on the views on economics and finance. The name of the candidates, what are they planning and how well their works are done are unrelated to our goals. We also obtain the releasing dates of those minutes during the process, which are the earliest accessible time of the FOMC minutes rather than the convening dates.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "% reldate contains the releasing dates of the minutes\n",
    "% jdata contains the rejoined cleaned data\n",
    "function [jdata, reldate] = clean(years)\n",
    "    txts = fetching(years);\n",
    "    reldate = zeros([length(txts), 1]);\n",
    "    data = cell(length(reldate), 1); % data contains the cleaned data split by paragraphs\n",
    "    for j = 1:length(txts)\n",
    "        txt = txts{j};\n",
    "        reldate(j) = time(txt); % this is a utility function for the releasing dates\n",
    "\n",
    "        txt = txt(txt ~= \"\");\n",
    "        be1 = find(contains(txt, \"The information reviewed\", \"IgnoreCase\", true), 1, \"first\");\n",
    "        be2 = find(contains(txt, \"The information provided\", \"IgnoreCase\", true), 1, \"first\");\n",
    "        be3 = find(contains(txt, \"The information received\", \"IgnoreCase\", true), 1, \"first\");\n",
    "        be4 = find(contains(txt, \"The information available\", \"IgnoreCase\", true), 1, \"first\");\n",
    "        be5 = find(contains(txt, \"The data available\", \"IgnoreCase\", true), 1, \"first\");\n",
    "        be6 = find(contains(txt, \"Staff Review of the Economic Situation\", \"IgnoreCase\", true), 1, \"first\") + 1;\n",
    "        be7 = find(contains(txt, \"Consumer spending\", \"IgnoreCase\", true), 1, \"first\");\n",
    "        be = min([be1, be2, be3, be4, be5, be6]);\n",
    "        if isempty(be)\n",
    "            be = be7;\n",
    "        end\n",
    "\n",
    "        if sum(contains(txt, \"At the conclusion of\", \"IgnoreCase\", true)) > 1\n",
    "            t = find(contains(txt, \"At the conclusion of\", \"IgnoreCase\", true)) - 1;\n",
    "            for h = 1:length(t)\n",
    "                if t(h) <= be\n",
    "                    continue;\n",
    "                else\n",
    "                    t = t(h);\n",
    "                    break;\n",
    "                end\n",
    "            end\n",
    "        else\n",
    "            t = find(contains(txt, \"At the conclusion of\", \"IgnoreCase\", true), 1, \"last\") - 1;\n",
    "        end\n",
    "\n",
    "        if sum(contains(txt, \"Committee Policy Action\", \"IgnoreCase\", true)) == 1\n",
    "            m = find(contains(txt, \"Committee Policy Action\", \"IgnoreCase\", true), 1, \"last\") + 1;\n",
    "        elseif sum(contains(txt, \"discussion of monetary policy\", \"IgnoreCase\", true)) > 1\n",
    "            m = find(contains(txt, \"discussion of monetary policy\", \"IgnoreCase\", true));\n",
    "            for h = 1:length(m)\n",
    "                if m(h) <= be\n",
    "                    continue;\n",
    "                else\n",
    "                    m = m(h);\n",
    "                    break;\n",
    "                end\n",
    "            end\n",
    "        else\n",
    "            m = find(contains(txt, \"discussion of monetary policy\", \"IgnoreCase\", true), 1, \"last\");\n",
    "        end\n",
    "        en = min([t, m]);\n",
    "\n",
    "        txt = txt(be:en);\n",
    "        data{j} = txt(strlength(txt) > 100);\n",
    "    end\n",
    "\n",
    "    jdata = cell(length(data), 1); % rejoin the lines to score one file as a whole\n",
    "    for i = 1:length(data)\n",
    "        jdata{i} = strjoin(data{i}, \" \");\n",
    "    end\n",
    "end"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the Sentiment Scores using FinBERT model\n",
    "\n",
    "FinBERT loads a pretrained BERT transformer model for sentiment analysis for financial text.\n",
    "\n",
    "\n",
    "<samp>[sentiment, scores] = finbert.sentimentModel(X, parameters)</samp> classifies the sentiment of the input <samp>1-by-numInputTokens</samp> <samp>-by-numObservations</samp> array of encoded tokens with the specified parameters. The output sentiment includes a categorical array with categories \"positive\", \"neural\"\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "function scores = fnbt(data, mdl, tokenizer, parameters)\n",
    "    scores = zeros([1, length(data)])';\n",
    "    for i = 1:length(data)\n",
    "        str = data{i};\n",
    "        tokens = encode(tokenizer, str);\n",
    "        X = padsequences(tokens, 2, \"PaddingValue\", mdl.Tokenizer.PaddingCode);\n",
    "        [~, scrs] = finbert.sentimentModel(X, parameters);\n",
    "        scores(i) = sum(scrs);\n",
    "    end\n",
    "end"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Releasing Dates Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "function release = time(txt)\n",
    "    ind = find(contains(txt, \"last update:\", \"IgnoreCase\", true), 1, \"last\");\n",
    "    str = txt(ind);\n",
    "    pattern = '(\\w+ \\d+, \\d{4})';\n",
    "    matches = regexp(str, pattern, 'match');\n",
    "    release = convertTo(datetime(matches{1}), \"yyyymmdd\");\n",
    "end"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"H_B9974303\"></a>\n",
    "\n",
    "### **Combining**\n",
    "\n",
    "This function is used for combining 2 pieces of swap rates with different frequencies. It will return a matrix that contains the dates and the corresponding swap rates. You can set freq as <samp>w</samp> for weekly data and <samp>d</samp> for daily data.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "function swaps = combine(file1, file2, freq) % combine 2 pieces of swap rates together\n",
    "    swaps1 = readtable(file1);\n",
    "    swaps2 = readtable(file2);\n",
    "\n",
    "    swaps1.DATE = convertTo(swaps1.DATE, \"yyyymmdd\");\n",
    "    swaps2.Date = convertTo(swaps2.Date, \"yyyymmdd\");\n",
    "    swaps2 = swaps2(height(swaps2):-1:1, 1:2);\n",
    "\n",
    "    if freq == \"w\" % you may choose weekly data\n",
    "        swaps2 = swaps2(1:7:end, 1:2);\n",
    "    end\n",
    "\n",
    "    if freq == \"w\"\n",
    "        mgind = find(swaps2.Date >= (swaps1.DATE(end) + 7), 1, \"last\");\n",
    "    else\n",
    "        mgind = find(swaps1.DATE <= swaps2.Date(1), 1, \"last\"); % use source 2 after September 30 2009\n",
    "    end\n",
    "    dates = [swaps1.DATE(1:mgind); swaps2.Date];\n",
    "\n",
    "    if freq == \"w\"\n",
    "        rates = [swaps1.WSWP2(1:mgind); swaps2.LastPrice]; % combined swap rates\n",
    "    else\n",
    "        rates = [swaps1.DSWP2(1:mgind); swaps2.LastPrice];\n",
    "    end\n",
    "\n",
    "    rates = fillmissing(rates, \"knn\", 5);\n",
    "    swaps(:, 1) = dates;\n",
    "    swaps(:, 2) = rates;\n",
    "end"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"H_08D5C750\"></a>\n",
    "\n",
    "### **Pairing**\n",
    "\n",
    "This function is used for pairing the predictors to the corresponding dates, it returns the latest values of the predictor corresponding to those dates. By choosing back = \"true\", you may add a \"one previous\" column of the predictor to the return matrix.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "function pfactor = pair(factor, resp, back)\n",
    "    % factor: a matrix that contains the dates and the values of a predictor\n",
    "    % resp: a matrix that contains the dates and the values of the swap rate\n",
    "    dates = factor(:, 1);\n",
    "    params = factor(:, 2);\n",
    "    r1 = resp(:, 1);\n",
    "    pfactor = zeros([length(r1), 1]);\n",
    "\n",
    "    for i = 1:length(r1)\n",
    "        idx1 = find(dates < r1(i), 1, \"last\");\n",
    "        idx2 = idx1 - 1;\n",
    "        pfactor(i, 1) = params(idx1);\n",
    "        if back % you may choose to obtain the one previous data\n",
    "            pfactor(i, 2) = params(idx2);\n",
    "        end\n",
    "    end\n",
    "end"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"H_12A78A0C\"></a>\n",
    "\n",
    "### **Merging**\n",
    "\n",
    "This function is used for merging the columns, including the dates, the latest updated swap rates and the predictors.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "% regress are the paired data for regression analysis\n",
    "function regress = merge(scores, freq)\n",
    "    if freq == \"w\"\n",
    "        file1 = \"WSWP2.csv\";\n",
    "        VIX = readtable(\"WVIX.csv\");\n",
    "    else\n",
    "        file1 = \"DSWP2.csv\";\n",
    "        VIX = readtable(\"DVIX.csv\");\n",
    "    end\n",
    "    file2 = \"swap-libor.xlsx\";\n",
    "    swaps = combine(file1, file2, freq);\n",
    "    vix(:, 1) = convertTo(VIX.Date, \"yyyymmdd\");\n",
    "    vix(:, 2) = fillmissing(VIX.Adj_Close, \"knn\", 5);\n",
    "\n",
    "    pscores = pair(scores, swaps(2:end, :), false);\n",
    "    pvix = pair(vix, swaps(2:end, :), true);\n",
    "    regress = [swaps(2:end, :), swaps(1:(end - 1), 2), pscores, pvix];\n",
    "end"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"H_29FF3972\"></a>\n",
    "\n",
    "### Using the F\\-test to Compare Two models\n",
    "\n",
    "This function is used for F\\-test. It returns the test result and its p\\-value.\n",
    "\n",
    "\n",
    "If the models have different numbers of parameters, the formula becomes:\n",
    "\n",
    "\n",
    " $F=\\frac{(SSE_1 -SSE_2 )/(df_1 -df_2 )}{SSE_2 /df_2 }$ .\n",
    "\n",
    "\n",
    " $SSE_1$ is the sum of squares of the simpler model, and $SSE_2$ is the sum of squares of the more complicated model.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "function [f, p] = ft(mmdl, mdl)\n",
    "    f = ((mdl.SSE - mmdl.SSE)/(mdl.DFE - mmdl.DFE))/(mmdl.SSE/mmdl.DFE);\n",
    "    p = 1 - fcdf(f, (mdl.DFE - mmdl.DFE), mmdl.DFE);\n",
    "end"
   ],
   "outputs": []
}
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATLAB (matlabkernel)",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "file_extension": ".m",
   "mimetype": "text/matlab",
   "name": "matlab",
   "nbconvert_exporter": "matlab",
   "pygments_lexer": "matlab",
   "version": "24.1.0.2603908"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}